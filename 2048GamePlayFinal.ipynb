{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "2048GamePlayFinal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bdadeveloper1/MachineLearningProjects/blob/main/2048GamePlayFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "P1Rmlv27etTh"
      },
      "source": [
        "# World Data Science Institute\n",
        "# 2048 Game Implementation using Deep Reinforcement Learning(Game Play)\n",
        "\n",
        "By Brandon Oppong-Antwi\n",
        "\n",
        "Adaption from: https://www.youtube.com/watch?v=b4XP2IcI-Bg&t=375s and https://github.com/navjindervirdee/2048-deep-reinforcement-learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esg7U_fzetUT"
      },
      "source": [
        "### Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUh3DXxOetUW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "986654e1-bc8c-4e48-b684-4ca0e884935f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "import random \n",
        "import math\n",
        "import time\n",
        "from tkinter import *\n",
        "!apt-get install -y xvfb # Install X Virtual Frame Buffer\n",
        "import os\n",
        "os.system('Xvfb :1 -screen 0 2400x2400x16  &')    # create virtual display with size 1600x1200 and 16 bit color. Color can be changed to 24 or 8\n",
        "os.environ['DISPLAY']=':1.0'    # tell X clients to use our virtual DISPLAY :1.0\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.4).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISE-sTluetVl"
      },
      "source": [
        "### Restore Architecture\n",
        "\n",
        "Restore the neural network architecture that we used in the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D05s7qkretVn"
      },
      "source": [
        "#conv layer1 depth\n",
        "depth1 = 128\n",
        "\n",
        "#conv layer2 depth\n",
        "depth2 = 128\n",
        "\n",
        "#input depth\n",
        "input_depth = 16\n",
        "\n",
        "#fully conneted hidden layer\n",
        "hidden_units = 256\n",
        "\n",
        "#output layer\n",
        "output_units = 4\n",
        "\n",
        "#shape of weights\n",
        "conv1_layer1_shape = [2,1,input_depth,depth1]\n",
        "conv1_layer2_shape = [2,1,depth1,depth2]\n",
        "conv2_layer1_shape = [1,2,input_depth,depth1]\n",
        "conv2_layer2_shape = [1,2,depth1,depth2]\n",
        "\n",
        "fc_layer1_w_shape = [3*4*depth1*2+ 4*2*depth2*2 + 3*3*depth2*2,hidden_units]\n",
        "fc_layer1_b_shape = [hidden_units]\n",
        "fc_layer2_w_shape = [hidden_units,output_units]\n",
        "fc_layer2_b_shape = [output_units]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0t0xq1YetV9"
      },
      "source": [
        "### Load The parameters\n",
        "\n",
        "Load the parameteres that we acquired from our training data, it should have displayed as csv file in a folder on your computer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcUW16f5etWD"
      },
      "source": [
        "parameters = dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ33Z7SqetW5"
      },
      "source": [
        "path = r'C:\\Users\\brandono\\2048-deep-reinforcement-learning\\Weights'\n",
        "\n",
        "parameters['conv1_layer1'] = np.array(pd.read_csv(r'conv1_layer1_weights.csv')['Weight']).reshape(conv1_layer1_shape)\n",
        "parameters['conv1_layer2'] = np.array(pd.read_csv(r'conv1_layer2_weights.csv')['Weight']).reshape(conv1_layer2_shape)\n",
        "parameters['conv2_layer1'] = np.array(pd.read_csv(r'conv2_layer1_weights.csv')['Weight']).reshape(conv2_layer1_shape)\n",
        "parameters['conv2_layer2'] = np.array(pd.read_csv(r'conv2_layer2_weights.csv')['Weight']).reshape(conv2_layer2_shape)\n",
        "parameters['fc_layer1_w'] = np.array(pd.read_csv(r'fc_layer1_weights.csv')['Weight']).reshape(fc_layer1_w_shape)\n",
        "parameters['fc_layer1_b'] = np.array(pd.read_csv(r'fc_layer1_biases.csv')['Weight']).reshape(fc_layer1_b_shape)\n",
        "parameters['fc_layer2_w'] = np.array(pd.read_csv(r'fc_layer2_weights.csv')['Weight']).reshape(fc_layer2_w_shape)\n",
        "parameters['fc_layer2_b'] = np.array(pd.read_csv(r'fc_layer2_biases.csv')['Weight']).reshape(fc_layer2_b_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6SURkUQetak"
      },
      "source": [
        "### Game Logic\n",
        "\n",
        "Same game logic as before. Sliding action is represented as a matrix that is transformed to reflect what a user would when playing the game"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK28sMz3etal"
      },
      "source": [
        "def new_game(n): #new game\n",
        "    matrix = []\n",
        "\n",
        "    for i in range(n):\n",
        "        matrix.append([0] * n)\n",
        "    return matrix\n",
        "\n",
        "def add_two(mat): #function that adds two or 4 into the matrix\n",
        "    empty_cells = []\n",
        "    for i in range(len(mat)):\n",
        "        for j in range(len(mat)):\n",
        "            if(mat[i][j]==0):\n",
        "                empty_cells.append((i,j))\n",
        "    if(len(empty_cells)==0):\n",
        "        return mat\n",
        "    index_pair = empty_cells[random.randint(0,len(empty_cells)-1)]\n",
        "    \n",
        "    num = np.random.random(1) #random number that generates the probability with 2 equal to 0.90 and 4 equal to 0.10\n",
        "    if(num>0.9):\n",
        "        mat[index_pair[0]][index_pair[1]]=4\n",
        "    else:\n",
        "        mat[index_pair[0]][index_pair[1]]=2\n",
        "    return mat\n",
        "\n",
        "def game_state(mat): #checks the game state\n",
        "    for i in range(len(mat)-1): #intentionally reduced to check the row on the right and below o(n)\n",
        "        for j in range(len(mat[0])-1): #more elegant to use exceptions but most likely this will be their solution\n",
        "            if mat[i][j]==mat[i+1][j] or mat[i][j+1]==mat[i][j]:\n",
        "                return 'not over'\n",
        "    for i in range(len(mat)): #check for any zero entries\n",
        "        for j in range(len(mat[0])):\n",
        "            if mat[i][j]==0:\n",
        "                return 'not over'\n",
        "    for k in range(len(mat)-1): #to check the left/right entries on the last row\n",
        "        if mat[len(mat)-1][k]==mat[len(mat)-1][k+1]:\n",
        "            return 'not over'\n",
        "    for j in range(len(mat)-1): #check up/down entries on last column\n",
        "        if mat[j][len(mat)-1]==mat[j+1][len(mat)-1]:\n",
        "            return 'not over'\n",
        "    return 'lose'\n",
        "\n",
        "def reverse(mat):\n",
        "    new=[]\n",
        "    for i in range(len(mat)):\n",
        "        new.append([])\n",
        "        for j in range(len(mat[0])):\n",
        "            new[i].append(mat[i][len(mat[0])-j-1])\n",
        "    return new\n",
        "\n",
        "def transpose(mat):\n",
        "    new=[]\n",
        "    for i in range(len(mat[0])):\n",
        "        new.append([])\n",
        "        for j in range(len(mat)):\n",
        "            new[i].append(mat[j][i])\n",
        "    return new\n",
        "\n",
        "def cover_up(mat):\n",
        "    new=[[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
        "    done=False\n",
        "    for i in range(4):\n",
        "        count=0\n",
        "        for j in range(4):\n",
        "            if mat[i][j]!=0:\n",
        "                new[i][count]=mat[i][j]\n",
        "                if j!=count:\n",
        "                    done=True\n",
        "                count+=1\n",
        "    return (new,done)\n",
        "\n",
        "def merge(mat):\n",
        "    done=False\n",
        "    score = 0\n",
        "    for i in range(4):\n",
        "         for j in range(3):\n",
        "             if mat[i][j]==mat[i][j+1] and mat[i][j]!=0:\n",
        "                 mat[i][j]*=2\n",
        "                 score += mat[i][j]   \n",
        "                 mat[i][j+1]=0\n",
        "                 done=True\n",
        "    return (mat,done,score)\n",
        "\n",
        "\n",
        "def up(game):\n",
        "        game=transpose(game)\n",
        "        game,done=cover_up(game)\n",
        "        temp=merge(game)\n",
        "        game=temp[0]\n",
        "        done=done or temp[1]\n",
        "        game=cover_up(game)[0]\n",
        "        game=transpose(game)\n",
        "        return (game,done,temp[2])\n",
        "\n",
        "def down(game):\n",
        "        game=reverse(transpose(game))\n",
        "        game,done=cover_up(game)\n",
        "        temp=merge(game)\n",
        "        game=temp[0]\n",
        "        done=done or temp[1]\n",
        "        game=cover_up(game)[0]\n",
        "        game=transpose(reverse(game))\n",
        "        return (game,done,temp[2])\n",
        "\n",
        "def left(game):\n",
        "        game,done=cover_up(game)\n",
        "        temp=merge(game)\n",
        "        game=temp[0]\n",
        "        done=done or temp[1]\n",
        "        game=cover_up(game)[0]\n",
        "        return (game,done,temp[2])\n",
        "\n",
        "def right(game):\n",
        "        game=reverse(game)\n",
        "        game,done=cover_up(game)\n",
        "        temp=merge(game)\n",
        "        game=temp[0]\n",
        "        done=done or temp[1]\n",
        "        game=cover_up(game)[0]\n",
        "        game=reverse(game)\n",
        "        return (game,done,temp[2])\n",
        "    \n",
        "\n",
        "def findemptyCell(mat):\n",
        "    count = 0\n",
        "    for i in range(len(mat)):\n",
        "        for j in range(len(mat)):\n",
        "            if(mat[i][j]==0):\n",
        "                count+=1\n",
        "    return count\n",
        "\n",
        "def change_values(X):\n",
        "    power_mat = np.zeros(shape=(1,4,4,16),dtype=np.float32)\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            if(X[i][j]==0):\n",
        "                power_mat[0][i][j][0] = 1.0\n",
        "            else:\n",
        "                power = int(math.log(X[i][j],2))\n",
        "                power_mat[0][i][j][power] = 1.0\n",
        "    return power_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTnACSicetay"
      },
      "source": [
        "### Controls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzNhO_N0eta1"
      },
      "source": [
        "controls = {0:up,1:left,2:right,3:down}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKiMVbRHetck"
      },
      "source": [
        "### Restore the Graph\n",
        "\n",
        "Restore the graph and the neural network architecture that we had from before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9VOSgWfetco"
      },
      "source": [
        "learned_graph = tf.Graph()\n",
        "\n",
        "with learned_graph.as_default():\n",
        "    \n",
        "    #input data\n",
        "    single_dataset = tf.placeholder(tf.float32,shape=(1,4,4,16))\n",
        "    \n",
        "    #weights\n",
        "    \n",
        "    #conv layer1 weights\n",
        "    conv1_layer1_weights = tf.constant(parameters['conv1_layer1'],dtype=tf.float32)\n",
        "    conv1_layer2_weights = tf.constant(parameters['conv1_layer2'],dtype=tf.float32)\n",
        "    \n",
        "    #conv layer2 weights\n",
        "    conv2_layer1_weights = tf.constant(parameters['conv2_layer1'],dtype=tf.float32)\n",
        "    conv2_layer2_weights = tf.constant(parameters['conv2_layer2'],dtype=tf.float32)\n",
        "    \n",
        "    #fully connected parameters\n",
        "    fc_layer1_weights = tf.constant(parameters['fc_layer1_w'],dtype=tf.float32)\n",
        "    fc_layer1_biases = tf.constant(parameters['fc_layer1_b'],dtype=tf.float32)\n",
        "    fc_layer2_weights = tf.constant(parameters['fc_layer2_w'],dtype=tf.float32)\n",
        "    fc_layer2_biases = tf.constant(parameters['fc_layer2_b'],dtype=tf.float32)\n",
        "    \n",
        "    \n",
        "    #model\n",
        "    def model(dataset):\n",
        "        #layer1\n",
        "        conv1 = tf.nn.conv2d(dataset,conv1_layer1_weights,[1,1,1,1],padding='VALID') \n",
        "        conv2 = tf.nn.conv2d(dataset,conv2_layer1_weights,[1,1,1,1],padding='VALID') \n",
        "\n",
        "        #layer1 relu activation\n",
        "        relu1 = tf.nn.relu(conv1)\n",
        "        relu2 = tf.nn.relu(conv2)\n",
        "\n",
        "        #layer2\n",
        "        conv11 = tf.nn.conv2d(relu1,conv1_layer2_weights,[1,1,1,1],padding='VALID') \n",
        "        conv12 = tf.nn.conv2d(relu1,conv2_layer2_weights,[1,1,1,1],padding='VALID') \n",
        "\n",
        "        conv21 = tf.nn.conv2d(relu2,conv1_layer2_weights,[1,1,1,1],padding='VALID') \n",
        "        conv22 = tf.nn.conv2d(relu2,conv2_layer2_weights,[1,1,1,1],padding='VALID') \n",
        "\n",
        "        #layer2 relu activation\n",
        "        relu11 = tf.nn.relu(conv11)\n",
        "        relu12 = tf.nn.relu(conv12)\n",
        "        relu21 = tf.nn.relu(conv21)\n",
        "        relu22 = tf.nn.relu(conv22)\n",
        "\n",
        "        #get shapes of all activations\n",
        "        shape1 = relu1.get_shape().as_list()\n",
        "        shape2 = relu2.get_shape().as_list()\n",
        "\n",
        "        shape11 = relu11.get_shape().as_list()\n",
        "        shape12 = relu12.get_shape().as_list()\n",
        "        shape21 = relu21.get_shape().as_list()\n",
        "        shape22 = relu22.get_shape().as_list()\n",
        "\n",
        "        #expansion\n",
        "        hidden1 = tf.reshape(relu1,[shape1[0],shape1[1]*shape1[2]*shape1[3]])\n",
        "        hidden2 = tf.reshape(relu2,[shape2[0],shape2[1]*shape2[2]*shape2[3]])\n",
        "\n",
        "        hidden11 = tf.reshape(relu11,[shape11[0],shape11[1]*shape11[2]*shape11[3]])\n",
        "        hidden12 = tf.reshape(relu12,[shape12[0],shape12[1]*shape12[2]*shape12[3]])\n",
        "        hidden21 = tf.reshape(relu21,[shape21[0],shape21[1]*shape21[2]*shape21[3]])\n",
        "        hidden22 = tf.reshape(relu22,[shape22[0],shape22[1]*shape22[2]*shape22[3]])\n",
        "\n",
        "        #concatenation\n",
        "        hidden = tf.concat([hidden1,hidden2,hidden11,hidden12,hidden21,hidden22],axis=1)\n",
        "\n",
        "        #full connected layers\n",
        "        hidden = tf.matmul(hidden,fc_layer1_weights) + fc_layer1_biases\n",
        "        hidden = tf.nn.relu(hidden)\n",
        "\n",
        "        #output layer\n",
        "        output = tf.matmul(hidden,fc_layer2_weights) + fc_layer2_biases\n",
        "\n",
        "        #return output\n",
        "        return output\n",
        "\n",
        "    #for single example\n",
        "    single_output = model(single_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKha00WFE6--"
      },
      "source": [
        "###Create the Game and Watch it Run\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8559CM91etcy"
      },
      "source": [
        "SIZE = 500\n",
        "GRID_LEN = 4\n",
        "GRID_PADDING = 10\n",
        "\n",
        "BACKGROUND_COLOR_GAME = \"#92877d\"\n",
        "BACKGROUND_COLOR_CELL_EMPTY = \"#9e948a\"\n",
        "BACKGROUND_COLOR_DICT = {   2:\"#eee4da\", 4:\"#ede0c8\", 8:\"#f2b179\", 16:\"#f59563\", \\\n",
        "                            32:\"#f67c5f\", 64:\"#f65e3b\", 128:\"#edcf72\", 256:\"#edcc61\", \\\n",
        "                            512:\"#edc850\", 1024:\"#edc53f\", 2048:\"#edc22e\" }\n",
        "\n",
        "CELL_COLOR_DICT = { 2:\"#776e65\", 4:\"#776e65\", 8:\"#f9f6f2\", 16:\"#f9f6f2\", \\\n",
        "                    32:\"#f9f6f2\", 64:\"#f9f6f2\", 128:\"#f9f6f2\", 256:\"#f9f6f2\", \\\n",
        "                    512:\"#f9f6f2\", 1024:\"#f9f6f2\", 2048:\"#f9f6f2\" }\n",
        "\n",
        "FONT = (\"Verdana\", 40, \"bold\")\n",
        "\n",
        "learned_sess = tf.Session(graph=learned_graph)\n",
        "\n",
        "class GameGrid(Frame):\n",
        "    def __init__(self):\n",
        "        Frame.__init__(self)\n",
        "\n",
        "        self.grid()\n",
        "        self.master.title('2048')\n",
        "\n",
        "        self.grid_cells = []\n",
        "        self.init_grid()\n",
        "        self.init_matrix()\n",
        "        self.update_grid_cells()\n",
        "        \n",
        "        self.wait_visibility()\n",
        "        self.after(10,self.make_move)\n",
        "        \n",
        "    def init_grid(self):\n",
        "        background = Frame(self, bg=BACKGROUND_COLOR_GAME, width=SIZE, height=SIZE)\n",
        "        background.grid()\n",
        "        for i in range(GRID_LEN):\n",
        "            grid_row = []\n",
        "            for j in range(GRID_LEN):\n",
        "                cell = Frame(background, bg=BACKGROUND_COLOR_CELL_EMPTY, width=SIZE/GRID_LEN, height=SIZE/GRID_LEN)\n",
        "                cell.grid(row=i, column=j, padx=GRID_PADDING, pady=GRID_PADDING)\n",
        "                # font = Font(size=FONT_SIZE, family=FONT_FAMILY, weight=FONT_WEIGHT)\n",
        "                t = Label(master=cell, text=\"\", bg=BACKGROUND_COLOR_CELL_EMPTY, justify=CENTER, font=FONT, width=4, height=2)\n",
        "                t.grid()\n",
        "                grid_row.append(t)\n",
        "\n",
        "            self.grid_cells.append(grid_row)\n",
        "\n",
        "    def gen(self):\n",
        "        return randint(0, GRID_LEN - 1)\n",
        "\n",
        "    def init_matrix(self):\n",
        "        self.matrix = new_game(4)\n",
        "\n",
        "        self.matrix=add_two(self.matrix)\n",
        "        self.matrix=add_two(self.matrix)\n",
        "\n",
        "    def update_grid_cells(self):\n",
        "        for i in range(GRID_LEN):\n",
        "            for j in range(GRID_LEN):\n",
        "                new_number = self.matrix[i][j]\n",
        "                if new_number == 0:\n",
        "                    self.grid_cells[i][j].configure(text=\"\", bg=BACKGROUND_COLOR_CELL_EMPTY)\n",
        "                else:\n",
        "                    self.grid_cells[i][j].configure(text=str(new_number), bg=BACKGROUND_COLOR_DICT[new_number], fg=CELL_COLOR_DICT[new_number])\n",
        "        self.update_idletasks()\n",
        "        \n",
        "    def make_move(self):\n",
        "        output = learned_sess.run([single_output],feed_dict = {single_dataset:change_values(self.matrix)})\n",
        "        move = np.argmax(output[0])\n",
        "        self.matrix,done,tempo = controls[move](self.matrix)\n",
        "        done=True\n",
        "        \n",
        "        if game_state(self.matrix)=='lose':\n",
        "            self.grid_cells[1][1].configure(text=\"You\",bg=BACKGROUND_COLOR_CELL_EMPTY)\n",
        "            self.grid_cells[1][2].configure(text=\"Lose!\",bg=BACKGROUND_COLOR_CELL_EMPTY)\n",
        "            done=False\n",
        "            \n",
        "        self.matrix = add_two(self.matrix)\n",
        "        self.update_grid_cells()\n",
        "        \n",
        "        \n",
        "        if(done==True):\n",
        "            self.after(7,self.make_move)\n",
        "        else:\n",
        "            time.sleep(3)\n",
        "            self.init_matrix()\n",
        "            self.update_grid_cells()\n",
        "            self.after(7,self.make_move)\n",
        "\n",
        "    def generate_next(self):\n",
        "        empty_cells = []\n",
        "        for i in range(len(mat)):\n",
        "            for j in range(len(mat)):\n",
        "                if(mat[i][j]==0):\n",
        "                    empty_cells.append((i,j))\n",
        "        if(len(empty_cells)==0):\n",
        "            return 0,false\n",
        "        index_pair = empty_cells[random.randint(0,len(empty_cells)-1)]\n",
        "        index = index_pair\n",
        "        self.matrix[index[0]][index[1]] = 2\n",
        "\n",
        "root = Tk()\n",
        "gamegrid = GameGrid()\n",
        "root.mainloop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BAlg2GHF6Oz"
      },
      "source": [
        "In the final version the game board and training should connect to give you this result. This is also what our training data look like. It is extremely interesting and fun to see this in realtime:\n",
        "\n",
        "\n",
        "\n",
        "![FinalGamePlay](https://github.com/navjindervirdee/2048-deep-reinforcement-learning/blob/master/Game%20Video/game.gif?raw=true)"
      ]
    }
  ]
}